{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoI/blY/cvSpTSXq/Bl6NQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUKIHEALTH/SUKIHEALTH/blob/main/Audio_to_structured_medical_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 0 - Install Dependencies**"
      ],
      "metadata": {
        "id": "GS14e5imd6mS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au1qvgMYd2Iv",
        "outputId": "f7657288-334d-4c33-a538-6c08d150e8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio faster-whisper soundfile openai transformers accelerate bitsandbytes huggingface_hub\n",
        "!sudo apt install -y ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfe923dd"
      },
      "source": [
        "!pip install -q safetensors"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 1 - Imports and Constants**"
      ],
      "metadata": {
        "id": "-w7QiOWAd9HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from faster_whisper import WhisperModel\n",
        "from huggingface_hub import HfApi\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "vWQm8Vd6d8sW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "GOOGLE_DRIVE_AUDIO_FOLDER = \"/content/drive/MyDrive/Recordings2025\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLnFxNinoLJf",
        "outputId": "2c28b941-567e-4bfd-b99e-7fcc67b1a2cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_audio_files(drive_folder):\n",
        "    if not os.path.exists(drive_folder):\n",
        "        raise ValueError(f\"üìÅ Folder not found: {drive_folder}\")\n",
        "    return sorted([\n",
        "        f for f in os.listdir(drive_folder)\n",
        "        if f.lower().endswith(('.mp3', '.wav', '.m4a'))\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "_Tg3Ur0poOcz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 2 - Load Models Globally (Whisper + Falcon)**"
      ],
      "metadata": {
        "id": "dgw5g4vMeCAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Whisper Model\n",
        "WHISPER_MODEL_SIZE = \"base\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "COMPUTE_TYPE = \"float16\" if DEVICE == \"cuda\" else \"int8\"\n",
        "whisper_model = WhisperModel(model_size_or_path=WHISPER_MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)\n",
        "\n",
        "# Falcon Model\n",
        "FALCON_MODEL_NAME = \"tiiuae/falcon-rw-1b\"\n",
        "falcon_tokenizer = AutoTokenizer.from_pretrained(FALCON_MODEL_NAME)\n",
        "falcon_model = AutoModelForCausalLM.from_pretrained(FALCON_MODEL_NAME, device_map=\"auto\")\n",
        "falcon_generator = pipeline(\"text-generation\", model=falcon_model, tokenizer=falcon_tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiVeUw2neB5C",
        "outputId": "aa2dc158-d9f4-4928-a75e-169942c98266"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 3 - Helper for Falcon Summary**"
      ],
      "metadata": {
        "id": "228_XdC0eFdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_structured_summary(transcript):\n",
        "    prompt = f\"\"\"You are an AI assistant helping with digital consultation notes generation:\n",
        "Transcript:\n",
        "\\\"\\\"\\\"{transcript}\\\"\\\"\\\"\n",
        "\n",
        "Format:\n",
        "Brief Summary: ...\n",
        "Presenting Complaint: ...\n",
        "History: ...\n",
        "Assessment / Working Diagnosis: ...\n",
        "Plan / Management: ...\n",
        "Safety-Netting & Follow-Up: ...\"\"\"\n",
        "\n",
        "    response = falcon_generator(prompt, max_new_tokens=512, do_sample=False)[0][\"generated_text\"]\n",
        "\n",
        "    summary = {\n",
        "        \"Brief Summary\": \"\",\n",
        "        \"Presenting Complaint\": \"\", \"History\": \"\",\n",
        "        \"Assessment / Working Diagnosis\": \"\", \"Plan / Management\": \"\",\n",
        "        \"Safety-Netting & Follow-Up\": \"\"\n",
        "    }\n",
        "\n",
        "    for line in response.split('\\n'):\n",
        "        for key in summary:\n",
        "            if line.startswith(key):\n",
        "                summary[key] = line.replace(f\"{key}:\", \"\").strip()\n",
        "\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "BzPFiyK_eFVm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 4 - Audio Preprocessing (Downsampling + Limits)**"
      ],
      "metadata": {
        "id": "042ZCJN4eNZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_DURATION_SEC = 4000\n",
        "\n",
        "def preprocess_audio_input(audio_file):\n",
        "    # audio_file: (sample_rate, np.ndarray)\n",
        "    if isinstance(audio_file, tuple):\n",
        "        sample_rate, audio_data = audio_file\n",
        "        if audio_data is None or len(audio_data) == 0:\n",
        "            raise ValueError(\"üìõ Empty Audio Data\")\n",
        "        duration_sec = len(audio_data) / sample_rate\n",
        "        if duration_sec > MAX_DURATION_SEC:\n",
        "            raise ValueError(f\"üö´ Max allowed duration is {MAX_DURATION_SEC}s. Yours: {duration_sec:.1f}s\")\n",
        "\n",
        "        # Downsample to 16k if needed\n",
        "        if sample_rate != 16000:\n",
        "            import librosa\n",
        "            audio_data = librosa.resample(audio_data.astype(np.float32), orig_sr=sample_rate, target_sr=16000)\n",
        "            sample_rate = 16000\n",
        "\n",
        "        tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "        sf.write(tmp.name, audio_data, sample_rate)\n",
        "        return tmp.name\n",
        "    else:\n",
        "        return audio_file if os.path.exists(audio_file) else None"
      ],
      "metadata": {
        "id": "dcdzrNPzeNSF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 5 - Full Pipeline**"
      ],
      "metadata": {
        "id": "z6tWgflHeP9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio(audio_file):\n",
        "    try:\n",
        "        audio_path = preprocess_audio_input(audio_file)\n",
        "        segments, info = whisper_model.transcribe(audio_path, vad_filter=True)\n",
        "        transcript = \" \".join([s.text for s in segments]).strip()\n",
        "\n",
        "        lang = info.language\n",
        "        print(f\"üó£Ô∏è Detected language: {lang} (p={info.language_probability:.2f})\")\n",
        "\n",
        "        if not transcript or len(transcript.split()) < 5:\n",
        "            return \"‚õî Not enough spoken data\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
        "\n",
        "        print(\"üß† Generating structured summary...\")\n",
        "        summary = generate_structured_summary(transcript)\n",
        "\n",
        "        return transcript, \\\n",
        "               summary[\"Brief Summary\"], summary[\"Presenting Complaint\"], summary[\"History\"], \\\n",
        "               summary[\"Assessment / Working Diagnosis\"], summary[\"Plan / Management\"], summary[\"Safety-Netting & Follow-Up\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error: {e}\", \"\", \"\", \"\", \"\", \"\", \"\"\n"
      ],
      "metadata": {
        "id": "29bKDwo9ePzW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 6 - Gradio UI**"
      ],
      "metadata": {
        "id": "M_e3pL_5eUzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## üéì AI Clinical Audio Assistant\")\n",
        "    gr.Markdown(\"üîä Upload, record, or select consultation audio ‚Üí Generate structured summary\")\n",
        "\n",
        "    with gr.Accordion(\"‚ÑπÔ∏è How to use\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "        - üé§ Use your microphone to record a consultation, or\n",
        "        - üéß Upload an existing .mp3/.wav/.m4a file, or\n",
        "        - üìÅ Choose a file stored in your Google Drive folder (auto-detected)\n",
        "        -----------------------------------------------------\n",
        "        Output includes a full transcript and structured summary with:\n",
        "        - Presenting Complaint\n",
        "        - History\n",
        "        - Diagnosis\n",
        "        - Plan\n",
        "        - Safety-netting remarks\n",
        "        \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        file_choices = list_audio_files(GOOGLE_DRIVE_AUDIO_FOLDER)\n",
        "        drive_file = gr.Dropdown(label=\"üìÅ Select Audio from Google Drive\", choices=file_choices)\n",
        "        mic_or_upload = gr.Audio(label=\"üéß Record or Upload Audio\", type=\"numpy\")\n",
        "\n",
        "    generate_btn = gr.Button(\"üöÄ Generate Clinical Summary\")\n",
        "\n",
        "    # Output fields\n",
        "    transcript = gr.Textbox(label=\"üó£Ô∏è Transcript\", lines=3, interactive=False)\n",
        "    brief = gr.Textbox(label=\"üìù Brief Summary\", lines=2)\n",
        "    complaint = gr.Textbox(label=\"‚ùì Presenting Complaint\", lines=2)\n",
        "    history = gr.Textbox(label=\"üìñ History\", lines=3)\n",
        "    assess = gr.Textbox(label=\"ü©∫ Diagnosis\", lines=2)\n",
        "    plan = gr.Textbox(label=\"üßæ Plan / Management\", lines=2)\n",
        "    safety = gr.Textbox(label=\"üõü Safety-Netting & Follow-Up\", lines=2)\n",
        "\n",
        "    # Logic: pick either Drive or mic/upload\n",
        "    def dispatch_input(uploaded_audio, drive_selection):\n",
        "        if uploaded_audio is not None:\n",
        "            return process_audio(uploaded_audio)\n",
        "        elif drive_selection:\n",
        "            full_path = os.path.join(GOOGLE_DRIVE_AUDIO_FOLDER, drive_selection)\n",
        "            return process_audio(full_path)\n",
        "        else:\n",
        "            return \"‚ùå Please provide or select an audio input.\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
        "\n",
        "    generate_btn.click(fn=dispatch_input,\n",
        "                       inputs=[mic_or_upload, drive_file],\n",
        "                       outputs=[transcript, brief, complaint, history, assess, plan, safety])\n",
        "\n",
        "app.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "S1XIomzVeUrq",
        "outputId": "69fc8804-bfc2-4430-d66f-4dba7cff56b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://717e0e7d95c3a2e92e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://717e0e7d95c3a2e92e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 7 - Save Results and Export CSV**"
      ],
      "metadata": {
        "id": "VVA6drN3eXi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Save outputs\n",
        "output_data = []\n",
        "\n",
        "def save_result_to_dataset(summary, output_file=\"/content/synthetic_dataset.csv\"):\n",
        "    output_data.append(summary)\n",
        "    df = pd.DataFrame(output_data)\n",
        "    df.to_csv(output_file, index=False)\n"
      ],
      "metadata": {
        "id": "6h55WoSDeXbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 8 - Upload Dataset to HF Hub**"
      ],
      "metadata": {
        "id": "-BNRNT2JebmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, create_repo, upload_file\n",
        "\n",
        "def upload_to_huggingface(csv_path, repo_id=\"your-username/synthetic-consultations\"):\n",
        "    # Assumes you‚Äôve logged in via `notebook_login()`\n",
        "    api = HfApi()\n",
        "    create_repo(repo_id, repo_type=\"dataset\", exist_ok=True)\n",
        "    upload_file(repo_id=repo_id, path_or_fileobj=csv_path, path_in_repo=\"synthetic_dataset.csv\", repo_type=\"dataset\")\n",
        "    print(f\"‚úÖ Uploaded to: https://huggingface.co/datasets/{repo_id}\")\n"
      ],
      "metadata": {
        "id": "OBJzUvrfebeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SECTION: 9 - Authenticate HuggingFace (1 Time)**"
      ],
      "metadata": {
        "id": "hHyasxwyeeMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "wo0_jLvIed65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BDWT3j4cehcW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xoa1hQVMehU8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}